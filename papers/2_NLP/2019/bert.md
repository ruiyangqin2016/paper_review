# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

Paper: https://arxiv.org/pdf/1810.04805.pdf <br/>
Code: https://github.com/google-research/bert <br/>
论文精读: [跟李沐学AI](https://www.bilibili.com/video/BV1PL411M7eQ?spm_id_from=333.999.0.0) <br/>
